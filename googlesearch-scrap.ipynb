{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: Could not find a version that satisfies the requirement googlesearch (from versions: none)\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[31mERROR: No matching distribution found for googlesearch\u001b[0m\u001b[31m\n",
      "\u001b[0m"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'googlesearch'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m get_ipython()\u001b[38;5;241m.\u001b[39msystem(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpip install googlesearch requests\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgooglesearch\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m search\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mrequests\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtime\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'googlesearch'"
     ]
    }
   ],
   "source": [
    "!pip install googlesearch requests\n",
    "from googlesearch import search\n",
    "import requests\n",
    "import time\n",
    "\n",
    "query = \"Glaucoma\"\n",
    "for url in search(f\"{query} pmc.ncbi.nlm.nih.gov/articles filetype:pdf\", 20):\n",
    "    try:\n",
    "        if url.endswith(\".pdf\"):\n",
    "            print(url) # Print the URL\n",
    "            response = requests.get(url, timeout=10)\n",
    "            if response.content and len(response.content) > 1000:\n",
    "                filename = url.split(\"/\")[-1]\n",
    "                with open(filename, \"wb\") as f:\n",
    "                    f.write(response.content)\n",
    "                print(\"✅\" + filename)\n",
    "        time.sleep(1)  # Be nice to the server\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Failed to download {url}: {e}\")\n",
    "\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "import tempfile\n",
    "import os\n",
    "from googlesearch import search\n",
    "import requests\n",
    "import time\n",
    "from typing import List, Tuple\n",
    "\n",
    "def search_and_download_pdfs(query: str, num_results: int = 20, download_dir: str = None, progress=gr.Progress()) -> List[Tuple]:\n",
    "    if not download_dir:\n",
    "        download_dir = tempfile.mkdtemp()\n",
    "    \n",
    "    results = []\n",
    "    urls = list(search(f\"{query} pmc.ncbi.nlm.nih.gov/articles filetype:pdf\", num_results))\n",
    "    \n",
    "    for i, url in enumerate(progress.tqdm(urls)):\n",
    "        if url.endswith(\".pdf\"):\n",
    "            try:\n",
    "                response = requests.get(url, timeout=10)\n",
    "                if response.content and len(response.content) > 1000:\n",
    "                    filename = url.split(\"/\")[-1]\n",
    "                    filepath = os.path.join(download_dir, filename)\n",
    "                    with open(filepath, \"wb\") as f:\n",
    "                        f.write(response.content)\n",
    "                    results.append((url, filepath, \"✅ Downloaded\"))\n",
    "                    yield results, download_dir, filepath  # Yield intermediate results\n",
    "                time.sleep(1)\n",
    "            except Exception as e:\n",
    "                results.append((url, None, f\"❌ Failed: {str(e)}\"))\n",
    "                yield results, download_dir, None\n",
    "    \n",
    "    return results, download_dir, None\n",
    "\n",
    "def create_ui():\n",
    "    with gr.Blocks() as app:\n",
    "        gr.Markdown(\"## PDF Search and Download\")\n",
    "        \n",
    "        with gr.Row():\n",
    "            with gr.Column(scale=3):\n",
    "                query = gr.Textbox(\n",
    "                    label=\"Search Query\",\n",
    "                    placeholder=\"Enter search terms...\",\n",
    "                    container=False\n",
    "                )\n",
    "            with gr.Column(scale=1):\n",
    "                num_results = gr.Slider(\n",
    "                    minimum=1,\n",
    "                    maximum=50,\n",
    "                    value=20,\n",
    "                    step=1,\n",
    "                    label=\"Number of Results\"\n",
    "                )\n",
    "        \n",
    "        with gr.Row():\n",
    "            search_btn = gr.Button(\"Search and Download\", variant=\"primary\")\n",
    "            clear_btn = gr.Button(\"Clear Results\")\n",
    "        \n",
    "        with gr.Row():\n",
    "            with gr.Column(scale=2):\n",
    "                results = gr.Dataframe(\n",
    "                    headers=[\"URL\", \"Local File\", \"Status\"],\n",
    "                    label=\"Search Results\",\n",
    "                    interactive=False,\n",
    "                    wrap=True\n",
    "                )\n",
    "                download_path = gr.Textbox(\n",
    "                    label=\"Download Directory\",\n",
    "                    interactive=False\n",
    "                )\n",
    "            \n",
    "            with gr.Column(scale=1):\n",
    "                pdf_viewer = gr.PDF(label=\"PDF Preview\")\n",
    "                status = gr.Status()\n",
    "        \n",
    "        def on_search(query_text, num):\n",
    "            status.update(\"Starting search...\")\n",
    "            current_pdf = None\n",
    "            for results_update, dir_path, pdf_path in search_and_download_pdfs(query_text, num):\n",
    "                if pdf_path:\n",
    "                    current_pdf = pdf_path\n",
    "                yield {\n",
    "                    results: results_update,\n",
    "                    download_path: dir_path,\n",
    "                    pdf_viewer: current_pdf if current_pdf else None,\n",
    "                    status: f\"Downloaded {len(results_update)} PDFs...\"\n",
    "                }\n",
    "            status.update(\"Search completed!\")\n",
    "        \n",
    "        def clear_outputs():\n",
    "            return {\n",
    "                results: None,\n",
    "                download_path: None,\n",
    "                pdf_viewer: None,\n",
    "                status: \"Cleared results\"\n",
    "            }\n",
    "\n",
    "        search_btn.click(\n",
    "            fn=on_search,\n",
    "            inputs=[query, num_results],\n",
    "            outputs=[results, download_path, pdf_viewer, status]\n",
    "        )\n",
    "        \n",
    "        clear_btn.click(\n",
    "            fn=clear_outputs,\n",
    "            outputs=[results, download_path, pdf_viewer, status]\n",
    "        )\n",
    "\n",
    "    return app\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    app = create_ui()\n",
    "    app.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "import tempfile\n",
    "import os\n",
    "from googlesearch import search\n",
    "import requests\n",
    "import time\n",
    "from typing import List, Tuple\n",
    "\n",
    "def search_and_download_pdfs(query: str, num_results: int = 20, download_dir: str = None, progress=gr.Progress()) -> List[Tuple]:\n",
    "    if not download_dir:\n",
    "        download_dir = tempfile.mkdtemp()\n",
    "    \n",
    "    results = []\n",
    "    urls = list(search(f\"{query} pmc.ncbi.nlm.nih.gov/articles filetype:pdf\", num_results))\n",
    "    \n",
    "    for i, url in enumerate(progress.tqdm(urls)):\n",
    "        if url.endswith(\".pdf\"):\n",
    "            try:\n",
    "                response = requests.get(url, timeout=10)\n",
    "                if response.content and len(response.content) > 1000:\n",
    "                    filename = url.split(\"/\")[-1]\n",
    "                    filepath = os.path.join(download_dir, filename)\n",
    "                    with open(filepath, \"wb\") as f:\n",
    "                        f.write(response.content)\n",
    "                    results.append((url, filepath, \"✅ Downloaded\"))\n",
    "                    yield results, download_dir, filepath  # Yield intermediate results\n",
    "                time.sleep(1)\n",
    "            except Exception as e:\n",
    "                results.append((url, None, f\"❌ Failed: {str(e)}\"))\n",
    "                yield results, download_dir, None\n",
    "    \n",
    "    return results, download_dir, None\n",
    "\n",
    "def create_ui():\n",
    "    with gr.Blocks() as app:\n",
    "        gr.Markdown(\"## PDF Search and Download\")\n",
    "        \n",
    "        with gr.Row():\n",
    "            with gr.Column(scale=3):\n",
    "                query = gr.Textbox(\n",
    "                    label=\"Search Query\",\n",
    "                    placeholder=\"Enter search terms...\",\n",
    "                    container=False\n",
    "                )\n",
    "            with gr.Column(scale=1):\n",
    "                num_results = gr.Slider(\n",
    "                    minimum=1,\n",
    "                    maximum=50,\n",
    "                    value=20,\n",
    "                    step=1,\n",
    "                    label=\"Number of Results\"\n",
    "                )\n",
    "        \n",
    "        with gr.Row():\n",
    "            search_btn = gr.Button(\"Search and Download\", variant=\"primary\")\n",
    "            clear_btn = gr.Button(\"Clear Results\")\n",
    "        \n",
    "        with gr.Row():\n",
    "            with gr.Column(scale=2):\n",
    "                results = gr.Dataframe(\n",
    "                    headers=[\"URL\", \"Local File\", \"Status\"],\n",
    "                    label=\"Search Results\",\n",
    "                    interactive=False,\n",
    "                    wrap=True\n",
    "                )\n",
    "                download_path = gr.Textbox(\n",
    "                    label=\"Download Directory\",\n",
    "                    interactive=False\n",
    "                )\n",
    "            \n",
    "            with gr.Column(scale=1):\n",
    "                pdf_viewer = gr.PDF(label=\"PDF Preview\")\n",
    "                status = gr.Status()\n",
    "        \n",
    "        def on_search(query_text, num):\n",
    "            status.update(\"Starting search...\")\n",
    "            current_pdf = None\n",
    "            for results_update, dir_path, pdf_path in search_and_download_pdfs(query_text, num):\n",
    "                if pdf_path:\n",
    "                    current_pdf = pdf_path\n",
    "                yield {\n",
    "                    results: results_update,\n",
    "                    download_path: dir_path,\n",
    "                    pdf_viewer: current_pdf if current_pdf else None,\n",
    "                    status: f\"Downloaded {len(results_update)} PDFs...\"\n",
    "                }\n",
    "            status.update(\"Search completed!\")\n",
    "        \n",
    "        def clear_outputs():\n",
    "            return {\n",
    "                results: None,\n",
    "                download_path: None,\n",
    "                pdf_viewer: None,\n",
    "                status: \"Cleared results\"\n",
    "            }\n",
    "\n",
    "        search_btn.click(\n",
    "            fn=on_search,\n",
    "            inputs=[query, num_results],\n",
    "            outputs=[results, download_path, pdf_viewer, status]\n",
    "        )\n",
    "        \n",
    "        clear_btn.click(\n",
    "            fn=clear_outputs,\n",
    "            outputs=[results, download_path, pdf_viewer, status]\n",
    "        )\n",
    "\n",
    "    return app\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    app = create_ui()\n",
    "    app.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
