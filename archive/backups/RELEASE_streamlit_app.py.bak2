import os, json, re, logging, asyncio, time, requests, pandas as pd, streamlit as st, openai, boto3, uuid, aiohttp, urllib3, random, html, smtplib
from datetime import datetime, timedelta
from dotenv import load_dotenv
from bs4 import BeautifulSoup
from googlesearch import search as google_search
from fake_useragent import UserAgent
from sqlalchemy import (
    func, create_engine, Column, BigInteger, Text, TIMESTAMP, ForeignKey, 
    Boolean, JSON, select, text, distinct, and_, Integer, String, Table, Float, Index
)
from sqlalchemy.dialects.postgresql import UUID, JSONB
from sqlalchemy.orm import declarative_base, sessionmaker, relationship, Session, joinedload
from sqlalchemy.exc import SQLAlchemyError
from botocore.exceptions import ClientError
from tenacity import retry, stop_after_attempt, wait_random_exponential, wait_fixed
from email_validator import validate_email, EmailNotValidError
from streamlit_option_menu import option_menu
from openai import OpenAI 
from typing import List, Optional, TYPE_CHECKING
from urllib.parse import urlparse, urlencode
from streamlit_tags import st_tags
import plotly.express as px
from requests.adapters import HTTPAdapter
from urllib3.util import Retry
from email.mime.text import MIMEText
from email.mime.multipart import MIMEMultipart
from contextlib import contextmanager
import multiprocessing
from multiprocessing import Process
import atexit
import threading

Base = declarative_base()

class Settings(Base):
    __tablename__ = 'settings'
    id = Column(BigInteger, primary_key=True)
    name = Column(Text)
    value = Column(Text)
    created_at = Column(TIMESTAMP(timezone=True))

class AIRequestLogs(Base):
    __tablename__ = 'ai_request_logs'
    id = Column(BigInteger, primary_key=True)
    function_name = Column(Text)
    prompt = Column(Text)
    response = Column(Text)
    model_used = Column(Text)
    created_at = Column(TIMESTAMP(timezone=True))
    lead_id = Column(BigInteger)
    email_campaign_id = Column(BigInteger)

class SearchTermEffectiveness(Base):
    __tablename__ = 'search_term_effectiveness'
    id = Column(BigInteger, primary_key=True)
    search_term_id = Column(BigInteger, ForeignKey('search_terms.id'))
    effectiveness_score = Column(Float)
    total_leads = Column(Integer)
    valid_leads = Column(Integer)
    created_at = Column(TIMESTAMP(timezone=True))
    search_term = relationship("SearchTerm", back_populates="effectiveness")

class AutomationLogs(Base):
    __tablename__ = 'automation_logs'
    id = Column(BigInteger, primary_key=True)
    campaign_id = Column(BigInteger)
    search_term_id = Column(BigInteger)
    leads_gathered = Column(BigInteger)
    emails_sent = Column(BigInteger)
    start_time = Column(TIMESTAMP(timezone=True))
    end_time = Column(TIMESTAMP(timezone=True))
    status = Column(Text)
    logs = Column(JSON)

class SearchProcesses(Base):
    __tablename__ = 'search_processes'
    id = Column(BigInteger, primary_key=True)
    search_terms = Column(JSON)

class SearchTermGroup(Base):
    __tablename__ = 'search_term_groups'
    __table_args__ = (
        Index('idx_group_name', 'name'),
        Index('idx_group_created', 'created_at'),
    )
    id = Column(BigInteger, primary_key=True)
    name = Column(Text, nullable=False)
    email_template = Column(Text)
    description = Column(Text)
    created_at = Column(TIMESTAMP(timezone=True), server_default=text('NOW()'))
    updated_at = Column(TIMESTAMP(timezone=True), onupdate=text('NOW()'))
    search_terms = relationship("SearchTerm", back_populates="group", cascade="all, delete-orphan")

class EmailSettings(Base):
    __tablename__ = 'email_settings'
    id = Column(BigInteger, primary_key=True)
    name = Column(Text, nullable=False)
    email = Column(Text, nullable=False)
    provider = Column(Text, nullable=False)
    smtp_server = Column(Text)
    smtp_port = Column(BigInteger)
    smtp_username = Column(Text)
    smtp_password = Column(Text)
    aws_access_key_id = Column(Text)
    aws_secret_access_key = Column(Text)
    aws_region = Column(Text)
    created_at = Column(TIMESTAMP(timezone=True))

# Import other models after defining our own
from models import (
    Campaign, LeadSource, SearchTerm, Lead, EmailCampaign, 
    Project, EmailTemplate, CampaignLead, KnowledgeBase
)

# Database configuration
DB_HOST = os.getenv("SUPABASE_DB_HOST")
DB_NAME = os.getenv("SUPABASE_DB_NAME") 
DB_USER = os.getenv("SUPABASE_DB_USER")
DB_PASSWORD = os.getenv("SUPABASE_DB_PASSWORD")
DB_PORT = os.getenv("SUPABASE_DB_PORT")

if not all([DB_HOST, DB_NAME, DB_USER, DB_PASSWORD, DB_PORT]):
    raise ValueError("One or more required database environment variables are not set")

DATABASE_URL = f"postgresql://{DB_USER}:{DB_PASSWORD}@{DB_HOST}:{DB_PORT}/{DB_NAME}"

# Create engine and session
engine = create_engine(DATABASE_URL, pool_size=20, max_overflow=0)
SessionLocal = sessionmaker(bind=engine)
Base = declarative_base()

if TYPE_CHECKING:
    from .models import Lead

@contextmanager
def db_session():
    session = SessionLocal()
    try:
        yield session
        session.commit()
    except Exception:
        session.rollback()
        raise
    finally:
        session.close()

class AIRequestLogs(Base):
    __tablename__ = 'ai_request_logs'
    id = Column(BigInteger, primary_key=True)
    function_name = Column(Text)
    prompt = Column(Text)
    response = Column(Text)
    model_used = Column(Text)
    created_at = Column(TIMESTAMP(timezone=True))
    lead_id = Column(BigInteger)
    email_campaign_id = Column(BigInteger)

class AIRequests(Base):
    __tablename__ = 'ai_requests'
    id = Column(BigInteger, primary_key=True)
    function_name = Column(Text)
    prompt = Column(Text)
    response = Column(Text)
    lead_id = Column(BigInteger)
    email_campaign_id = Column(BigInteger)
    model_used = Column(Text)
    created_at = Column(TIMESTAMP(timezone=True))
    logs = Column(JSON)

class AlembicVersion(Base):
    __tablename__ = 'alembic_version'
    version_num = Column(String, primary_key=True)

class AutomationErrors(Base):
    __tablename__ = 'automation_errors'
    id = Column(BigInteger, primary_key=True)
    task_type = Column(Text)
    error_type = Column(Text)
    error_message = Column(Text)
    created_at = Column(TIMESTAMP(timezone=True))

class AutomationJobs(Base):
    __tablename__ = 'automation_jobs'
    id = Column(UUID, primary_key=True)
    status = Column(String, nullable=False)
    current_group = Column(String)
    current_position = Column(Integer)
    total_emails_sent = Column(Integer)
    group_emails_sent = Column(Integer)
    distribution_method = Column(String)
    created_at = Column(TIMESTAMP(timezone=True))
    updated_at = Column(TIMESTAMP(timezone=True))
    loop_interval = Column(Integer)
    max_emails_per_group = Column(Integer)
    loop_automation = Column(Boolean)

class AutomationRules(Base):
    __tablename__ = 'automation_rules'
    id = Column(BigInteger, primary_key=True)
    name = Column(Text)
    rule_type = Column(Text)
    condition = Column(Text)
    threshold = Column(Float)
    action = Column(Text)
    notification_email = Column(Text)
    is_active = Column(Boolean)
    created_at = Column(TIMESTAMP(timezone=True))

class AutomationSchedules(Base):
    __tablename__ = 'automation_schedules'
    id = Column(BigInteger, primary_key=True)
    name = Column(Text)
    task_type = Column(Text)
    frequency = Column(Text)
    start_date = Column(TIMESTAMP(timezone=True))
    end_date = Column(TIMESTAMP(timezone=True))
    time_of_day = Column(Text)
    created_at = Column(TIMESTAMP(timezone=True))

class AutomationSettings(Base):
    __tablename__ = 'automation_settings'
    id = Column(Integer, primary_key=True)
    status = Column(Text)
    distribution_method = Column(Text)
    updated_at = Column(TIMESTAMP(timezone=True))

class AutomationState(Base):
    __tablename__ = 'automation_state'
    id = Column(BigInteger, primary_key=True)
    current_group_id = Column(BigInteger)
    current_term_id = Column(BigInteger)
    processed_groups = Column(JSONB)
    group_metrics = Column(JSONB)
    term_metrics = Column(JSONB)
    emails_sent = Column(BigInteger)
    leads_found = Column(BigInteger)
    last_updated = Column(TIMESTAMP(timezone=True))

class AutomationStatus(Base):
    __tablename__ = 'automation_status'
    id = Column(BigInteger, primary_key=True)
    status = Column(Text)
    started_at = Column(TIMESTAMP(timezone=True))
    stopped_at = Column(TIMESTAMP(timezone=True))
    paused_at = Column(TIMESTAMP(timezone=True))
    created_at = Column(TIMESTAMP(timezone=True))

class AutomationTasks(Base):
    __tablename__ = 'automation_tasks'
    id = Column(BigInteger, primary_key=True)
    task_type = Column(Text)
    status = Column(Text)
    progress = Column(Integer)
    started_at = Column(TIMESTAMP(timezone=True))
    completed_at = Column(TIMESTAMP(timezone=True))
    eta = Column(TIMESTAMP(timezone=True))
    logs = Column(JSON)
    created_at = Column(TIMESTAMP(timezone=True))

class CampaignLeads(Base):
    __tablename__ = 'campaign_leads'
    id = Column(BigInteger, primary_key=True)
    campaign_id = Column(BigInteger)
    lead_id = Column(BigInteger)
    status = Column(Text)
    created_at = Column(TIMESTAMP(timezone=True))

class Campaigns(Base):
    __tablename__ = 'campaigns'
    id = Column(BigInteger, primary_key=True)
    campaign_name = Column(Text)
    campaign_type = Column(Text)
    project_id = Column(BigInteger)
    created_at = Column(TIMESTAMP(timezone=True))
    auto_send = Column(Boolean)
    loop_automation = Column(Boolean)
    ai_customization = Column(Boolean)
    max_emails_per_group = Column(BigInteger)
    loop_interval = Column(BigInteger)
    schedule_config = Column(JSON)
    ab_test_config = Column(JSON)
    sequence_config = Column(JSON)
    status = Column(Text)
    updated_at = Column(TIMESTAMP(timezone=True))
    progress = Column(Integer)
    total_tasks = Column(Integer)
    completed_tasks = Column(Integer)

class EmailCampaigns(Base):
    __tablename__ = 'email_campaigns'
    id = Column(BigInteger, primary_key=True)
    campaign_id = Column(BigInteger)
    lead_id = Column(BigInteger)
    template_id = Column(BigInteger)
    customized_subject = Column(Text)
    customized_content = Column(Text)
    original_subject = Column(Text)
    original_content = Column(Text)
    status = Column(Text)
    engagement_data = Column(JSON)
    message_id = Column(Text)
    tracking_id = Column(Text)
    sent_at = Column(TIMESTAMP(timezone=True))
    ai_customized = Column(Boolean)
    opened_at = Column(TIMESTAMP(timezone=True))
    clicked_at = Column(TIMESTAMP(timezone=True))
    open_count = Column(BigInteger)
    click_count = Column(BigInteger)

class EmailQuotas(Base):
    __tablename__ = 'email_quotas'
    id = Column(BigInteger, primary_key=True)
    email_settings_id = Column(BigInteger)
    daily_sent = Column(BigInteger)
    last_reset = Column(TIMESTAMP(timezone=True))

class EmailTemplates(Base):
    __tablename__ = 'email_templates'
    id = Column(BigInteger, primary_key=True)
    campaign_id = Column(BigInteger)
    template_name = Column(Text)
    subject = Column(Text)
    body_content = Column(Text)
    created_at = Column(TIMESTAMP(timezone=True))
    is_ai_customizable = Column(Boolean)
    language = Column(Text)

class KnowledgeBase(Base):
    __tablename__ = 'knowledge_base'
    id = Column(BigInteger, primary_key=True)
    project_id = Column(BigInteger, nullable=False)
    kb_name = Column(Text)
    kb_bio = Column(Text)
    kb_values = Column(Text)
    contact_name = Column(Text)
    contact_role = Column(Text)
    contact_email = Column(Text)
    company_description = Column(Text)
    company_mission = Column(Text)
    company_target_market = Column(Text)
    company_other = Column(Text)
    product_name = Column(Text)
    product_description = Column(Text)
    product_target_customer = Column(Text)
    product_other = Column(Text)
    other_context = Column(Text)
    example_email = Column(Text)
    tone_of_voice = Column(Text)
    communication_style = Column(Text)
    response_templates = Column(JSON)
    keywords = Column(JSON)
    context_variables = Column(JSON)
    ai_customization_rules = Column(JSON)
    created_at = Column(TIMESTAMP(timezone=True))
    updated_at = Column(TIMESTAMP(timezone=True))

class LeadSources(Base):
    __tablename__ = 'lead_sources'
    id = Column(BigInteger, primary_key=True)
    lead_id = Column(BigInteger)
    search_term_id = Column(BigInteger)
    url = Column(Text)
    domain = Column(Text)
    page_title = Column(Text)
    meta_description = Column(Text)
    scrape_duration = Column(Text)
    meta_tags = Column(Text)
    phone_numbers = Column(Text)
    content = Column(Text)
    tags = Column(Text)
    http_status = Column(BigInteger)
    domain_effectiveness = Column(JSON)
    correlation_data = Column(JSON)
    created_at = Column(TIMESTAMP(timezone=True))

class Leads(Base):
    __tablename__ = 'leads'
    id = Column(BigInteger, primary_key=True)
    email = Column(Text)
    phone = Column(Text)
    first_name = Column(Text)
    last_name = Column(Text)
    company = Column(Text)
    job_title = Column(Text)
    lead_score = Column(BigInteger)
    status = Column(Text)
    source_category = Column(Text)
    created_at = Column(TIMESTAMP(timezone=True))
    is_processed = Column(Boolean)

class OptimizedSearchTerms(Base):
    __tablename__ = 'optimized_search_terms'
    id = Column(BigInteger, primary_key=True)
    original_term_id = Column(BigInteger)
    term = Column(Text)
    created_at = Column(TIMESTAMP(timezone=True))

class Projects(Base):
    __tablename__ = 'projects'
    id = Column(BigInteger, primary_key=True)
    project_name = Column(Text)
    created_at = Column(TIMESTAMP(timezone=True))

class SearchGroups(Base):
    __tablename__ = 'search_groups'
    id = Column(UUID, primary_key=True)
    name = Column(String, nullable=False)
    description = Column(Text)
    emails_sent = Column(Integer)
    created_at = Column(TIMESTAMP(timezone=True))
    updated_at = Column(TIMESTAMP(timezone=True))

class SearchTerm(Base):
    __tablename__ = 'search_terms'
    __table_args__ = (
        Index('idx_term', 'term'),
        Index('idx_term_group', 'group_id'),
        Index('idx_term_campaign', 'campaign_id'),
        Index('idx_term_created', 'created_at'),
    )
    id = Column(BigInteger, primary_key=True)
    term = Column(Text, nullable=False)
    group_id = Column(BigInteger, ForeignKey('search_term_groups.id', ondelete='SET NULL'))
    campaign_id = Column(BigInteger, ForeignKey('campaigns.id', ondelete='CASCADE'))
    category = Column(Text)
    language = Column(Text, default='ES')
    created_at = Column(TIMESTAMP(timezone=True), server_default=text('NOW()'))
    updated_at = Column(TIMESTAMP(timezone=True), onupdate=text('NOW()'))
    effectiveness_score = Column(Float, default=0.0)
    last_used = Column(TIMESTAMP(timezone=True))
    is_active = Column(Boolean, default=True)
    group = relationship("SearchTermGroup", back_populates="search_terms")
    campaign = relationship("Campaign", back_populates="search_terms")
    optimized_terms = relationship("OptimizedSearchTerm", back_populates="original_term")
    lead_sources = relationship("LeadSource", back_populates="search_term")
    effectiveness = relationship("SearchTermEffectiveness", back_populates="search_term", uselist=False)

class ProcessManager:
    def __init__(self):
        self._processes = {}
        self._lock = threading.Lock()
        
    def start_process(self, process_id: str, target: callable, args: tuple) -> bool:
        with self._lock:
            if process_id in self._processes and self._processes[process_id].is_alive():
                return False
                
            process = Process(target=target, args=args)
            process.daemon = True
            process.start()
            self._processes[process_id] = process
            
            with db_session() as session:
                session.add(BackgroundProcessState(
                    process_id=process_id,
                    status='running',
                    started_at=datetime.utcnow()
                ))
                session.commit()
            return True
    
    def stop_process(self, process_id: str) -> bool:
        """Stop a running process"""
        with self._lock:
            process = self._processes.get(process_id)
            if process and process.is_alive():
                process.terminate()
                process.join(timeout=1)
                del self._processes[process_id]
                return True
            return False
            
    def register_process(self, process_id: str, process_type: str) -> None:
        """Register a process in the database"""
        with db_session() as session:
            session.add(BackgroundProcessState(
                process_id=process_id,
                status='registered',
                started_at=datetime.utcnow()
            ))
            session.commit()

# Create or update tables
def init_db():
    Base.metadata.create_all(engine)

def delete_email_setting(setting_id):
    with db_session() as session:
        setting = session.query(EmailSettings).get(setting_id)
        if setting:
            session.delete(setting)
            session.commit()
            st.success(f"Deleted {setting.name}")
            st.session_state.edit_id = "New Setting"
        else:
            st.error(f"Setting with id {setting_id} not found")

def update_edit_id(selected_option):
    st.session_state.edit_id = selected_option

def send_email_ses(session, from_email, to_email, subject, body, charset='UTF-8', reply_to=None, ses_client=None):
    email_settings = session.query(EmailSettings).filter_by(email=from_email).first()
    if not email_settings:
        logging.error(f"No email settings found for {from_email}")
        return None, None

    tracking_id = str(uuid.uuid4())
    tracking_pixel_url = f"https://autoclient-email-analytics.trigox.workers.dev/track?{urlencode({'id': tracking_id, 'type': 'open'})}"
    wrapped_body = wrap_email_body(body)
    tracked_body = wrapped_body.replace('</body>', f'<img src="{tracking_pixel_url}" width="1" height="1" style="display:none;"/></body>')

    soup = BeautifulSoup(tracked_body, 'html.parser')
    for a in soup.find_all('a', href=True):
        original_url = a['href']
        tracked_url = f"https://autoclient-email-analytics.trigox.workers.dev/track?{urlencode({'id': tracking_id, 'type': 'click', 'url': original_url})}"
        a['href'] = tracked_url
    tracked_body = str(soup)

    try:
        test_response = requests.get(f"https://autoclient-email-analytics.trigox.workers.dev/test", timeout=5)
        if test_response.status_code != 200:
            logging.warning("Analytics worker is down. Using original URLs.")
            tracked_body = wrapped_body
    except requests.RequestException:
        logging.warning("Failed to reach analytics worker. Using original URLs.")
        tracked_body = wrapped_body

    try:
        if email_settings.provider == 'ses':
            if ses_client is None:
                aws_session = boto3.Session(
                    aws_access_key_id=email_settings.aws_access_key_id,
                    aws_secret_access_key=email_settings.aws_secret_access_key,
                    region_name=email_settings.aws_region
                )
                ses_client = aws_session.client('ses')
            
            response = ses_client.send_email(
                Source=from_email,
                Destination={'ToAddresses': [to_email]},
                Message={
                    'Subject': {'Data': subject, 'Charset': charset},
                    'Body': {'Html': {'Data': tracked_body, 'Charset': charset}}
                },
                ReplyToAddresses=[reply_to] if reply_to else []
            )
            return response, tracking_id
        elif email_settings.provider == 'smtp':
            msg = MIMEMultipart()
            msg['From'] = from_email
            msg['To'] = to_email
            msg['Subject'] = subject
            if reply_to:
                msg['Reply-To'] = reply_to
            msg.attach(MIMEText(tracked_body, 'html'))

            with smtplib.SMTP(email_settings.smtp_server, email_settings.smtp_port) as server:
                server.starttls()
                server.login(email_settings.smtp_username, email_settings.smtp_password)
                server.send_message(msg)
            return {'MessageId': f'smtp-{uuid.uuid4()}'}, tracking_id
        else:
            logging.error(f"Unknown email provider: {email_settings.provider}")
            return None, None
    except Exception as e:
        logging.error(f"Error sending email: {str(e)}")
        return None, None

def save_email_campaign(session, lead_email, template_id, status, sent_at, subject, message_id, email_body):
    try:
        lead = session.query(Lead).filter_by(email=lead_email).first()
        if not lead:
            logging.error(f"Lead with email {lead_email} not found.")
            return

        new_campaign = EmailCampaign(
            lead_id=lead.id,
            template_id=template_id,
            status=status,
            sent_at=sent_at,
            customized_subject=subject or "No subject",
            message_id=message_id or f"unknown-{uuid.uuid4()}",
            customized_content=email_body or "No content",
            campaign_id=get_active_campaign_id(),
            tracking_id=str(uuid.uuid4())
        )
        session.add(new_campaign)
        session.commit()
    except Exception as e:
        logging.error(f"Error saving email campaign: {str(e)}")
        session.rollback()

def update_log(log_container, message, level='info', process_id=None):
    # Define log icons for visual feedback
    icon = {
        'info': '🔵',
        'success': '🟢',
        'warning': '🟠',
        'error': '🔴',
        'email_sent': '🟣',
        'task_start': '▶️',
        'task_end': '⏹️',
        'reconnect': '🔄'
    }.get(level, '⚪')
    
    timestamp = datetime.now().strftime("%H:%M:%S")
    log_entry = f"{icon} [{timestamp}] {message}"
    
    # Store in database for persistence
    if process_id:
        with db_session() as session:
            process = session.query(SearchProcess).get(process_id)
            if process:
                if not process.logs:
                    process.logs = []
                process.logs.append({
                    'timestamp': datetime.utcnow().isoformat(),
                    'message': message,
                    'level': level
                })
                session.commit()
    
    # Initialize session state for logs if not exists
    if 'log_entries' not in st.session_state:
        st.session_state.log_entries = []
        st.session_state.last_update = datetime.now()
    
    st.session_state.log_entries.append(log_entry)
    st.session_state.last_update = datetime.now()
    
    # Keep only last 1000 entries to prevent memory issues
    if len(st.session_state.log_entries) > 1000:
        st.session_state.log_entries = st.session_state.log_entries[-1000:]
    
    # Create scrollable log container with auto-scroll and improved styling
    log_html = f"""
        <div style='
            background: linear-gradient(to bottom, #f0f2f6, #e6e9ef);
            border-radius: 8px;
            padding: 15px;
            margin-bottom: 15px;
            box-shadow: 0 2px 4px rgba(0,0,0,0.1);
        '>
            <div class="log-header" style='
                display: flex;
                justify-content: space-between;
                align-items: center;
                margin-bottom: 10px;
                font-size: 0.9em;
                color: #555;
            '>
                <span>Live Logs</span>
                <span>Last Update: {st.session_state.last_update.strftime("%H:%M:%S")}</span>
            </div>
            <div id="log-container" style='
                height: 300px;
                overflow-y: auto;
                font-family: "SFMono-Regular", Consolas, "Liberation Mono", Menlo, Courier, monospace;
                font-size: 0.9em;
                line-height: 1.5;
                padding: 12px;
                background: rgba(255,255,255,0.95);
                border-radius: 6px;
                border: 1px solid rgba(0,0,0,0.1);
            '>
                {'<br>'.join(st.session_state.log_entries)}
            </div>
        </div>
            <script>
            function scrollToBottom() {{
                var container = document.getElementById('log-container');
                if (container) {{
                    container.scrollTop = container.scrollHeight;
                }}
            }}
            
            // Initial scroll
            scrollToBottom();
            
            // Set up a mutation observer to watch for changes
            var observer = new MutationObserver(scrollToBottom);
            var container = document.getElementById('log-container');
            if (container) {{
                observer.observe(container, {{ childList: true, subtree: true }});
            }}
            
            // Auto-refresh functionality
            function checkForUpdates() {{
                if (document.visibilityState === 'visible') {{
                    // Trigger Streamlit rerun only if tab is visible
                    window.streamlitRerun && window.streamlitRerun();
                }}
            }}
            
            // Check for updates every 5 seconds when tab is visible
            setInterval(checkForUpdates, 5000);
            
            // Handle visibility changes
            document.addEventListener('visibilitychange', () => {{
                if (document.visibilityState === 'visible') {{
                    checkForUpdates();
                }}
            }});
            </script>
    """
    if log_container is not None:
        log_container.markdown(log_html, unsafe_allow_html=True)

def optimize_search_term(search_term, language):
    if language == 'english':
        return f'"{search_term}" email OR contact OR "get in touch" site:.com'
    elif language == 'spanish':
        return f'"{search_term}" correo OR contacto OR "ponte en contacto" site:.es'
    return search_term

def shuffle_keywords(term):
    words = term.split()
    random.shuffle(words)
    return ' '.join(words)

def is_valid_email(email):
    """Validate email format and syntax"""
    try:
        validate_email(email)
        pattern = r'^[\w\.-]+@[\w\.-]+\.\w+$'
        return bool(re.match(pattern, email))
    except EmailNotValidError:
        return False

def get_domain_from_url(url):
    """Extract domain from URL"""
    return urlparse(url).netloc

def extract_emails_from_html(html_content):
    pattern = r'\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\.[A-Z|a-z]{2,}\b'
    return re.findall(pattern, html_content)

def extract_info_from_page(soup):
    name = soup.find('meta', {'name': 'author'})
    name = name['content'] if name else ''
    
    company = soup.find('meta', {'property': 'og:site_name'})
    company = company['content'] if company else ''
    
    job_title = soup.find('meta', {'name': 'job_title'})
    job_title = job_title['content'] if job_title else ''
    
    return name, company, job_title

def manual_search(session, terms, num_results, ignore_previously_fetched=True, optimize_english=False, optimize_spanish=False, shuffle_keywords_option=False, language='ES', enable_email_sending=True, log_container=None, from_email=None, reply_to=None, email_template=None):
    # Prevent multiple concurrent searches
    if 'search_in_progress' in st.session_state and st.session_state.search_in_progress:
        log_container.error("A search is already in progress. Please wait for it to complete.")
        return

    try:
        st.session_state.search_in_progress = True
        
        # Save search state for recovery
        st.session_state.last_search = {
            'terms': terms,
            'num_results': num_results,
            'language': language
        }
        
        ua, results, total_leads, domains_processed = UserAgent(), [], 0, set()
        for original_term in terms:
            try:
                search_term_id = add_or_get_search_term(session, original_term, get_active_campaign_id())
                search_term = shuffle_keywords(original_term) if shuffle_keywords_option else original_term
                search_term = optimize_search_term(search_term, 'english' if optimize_english else 'spanish') if optimize_english or optimize_spanish else search_term
                update_log(log_container, f"Searching for '{original_term}' (Used '{search_term}')")
                for url in google_search(search_term, num_results, lang=language):
                    domain = get_domain_from_url(url)
                    if ignore_previously_fetched and domain in domains_processed:
                        update_log(log_container, f"Skipping Previously Fetched: {domain}", 'warning')
                        continue
                    update_log(log_container, f"Fetching: {url}")
                    try:
                        if not url.startswith(('http://', 'https://')):
                            url = 'http://' + url
                        response = requests.get(url, timeout=10, verify=False, headers={'User-Agent': ua.random})
                        response.raise_for_status()
                        html_content, soup = response.text, BeautifulSoup(response.text, 'html.parser')
                        emails = extract_emails_from_html(html_content)
                        update_log(log_container, f"Found {len(emails)} email(s) on {url}", 'success')
                        for email in filter(is_valid_email, emails):
                            if domain not in domains_processed:
                                name, company, job_title = extract_info_from_page(soup)
                                lead = save_lead(session, email=email, first_name=name, company=company, job_title=job_title, url=url, search_term_id=search_term_id, created_at=datetime.utcnow())
                                if lead:
                                    total_leads += 1
                                    results.append({
                                        'Email': email, 'URL': url, 'Lead Source': original_term, 
                                        'Title': get_page_title(html_content), 'Description': get_page_description(html_content),
                                        'Tags': [], 'Name': name, 'Company': company, 'Job Title': job_title,
                                        'Search Term ID': search_term_id
                                    })
                                    update_log(log_container, f"Saved lead: {email}", 'success')
                                    domains_processed.add(domain)
                                    if enable_email_sending:
                                        if not from_email or not email_template:
                                            update_log(log_container, "Email sending is enabled but from_email or email_template is not provided", 'error')
                                            return {"total_leads": total_leads, "results": results}

                                        template = session.query(EmailTemplate).filter_by(id=int(email_template.split(":")[0])).first()
                                        if not template:
                                            update_log(log_container, "Email template not found", 'error')
                                            return {"total_leads": total_leads, "results": results}

                                        wrapped_content = wrap_email_body(template.body_content)
                                        response, tracking_id = send_email_ses(session, from_email, email, template.subject, wrapped_content, reply_to=reply_to)
                                        if response:
                                            update_log(log_container, f"Sent email to: {email}", 'email_sent')
                                            save_email_campaign(session, email, template.id, 'Sent', datetime.utcnow(), template.subject, response['MessageId'], wrapped_content)
                                        else:
                                            update_log(log_container, f"Failed to send email to: {email}", 'error')
                                            save_email_campaign(session, email, template.id, 'Failed', datetime.utcnow(), template.subject, None, wrapped_content)
                                    break
                    except requests.RequestException as e:
                        update_log(log_container, f"Error processing URL {url}: {str(e)}", 'error')
            except Exception as e:
                update_log(log_container, f"Error processing term '{original_term}': {str(e)}", 'error')
        update_log(log_container, f"Total leads found: {total_leads}", 'info')
        return {"total_leads": total_leads, "results": results}
    except Exception as e:
        log_container.error(f"Search failed: {str(e)}")
        if hasattr(st.session_state, 'last_search'):
            log_container.info("You can retry the search with the same parameters.")
    finally:
        st.session_state.search_in_progress = False

def generate_or_adjust_email_template(prompt, kb_info=None, current_template=None):
    """Generate or adjust email template using AI with knowledge base context"""
    if not kb_info:
        return current_template or prompt

    # Enhance prompt with knowledge base context
    enhanced_prompt = f"""
    Context:
    - Tone of Voice: {kb_info.get('tone_of_voice', 'Professional')}
    - Communication Style: {kb_info.get('communication_style', 'Direct')}
    - Company Description: {kb_info.get('company_description', '')}
    - Target Market: {kb_info.get('company_target_market', '')}
    
    Original Template or Prompt:
    {prompt}
    
    Please generate an email that:
    1. Matches the specified tone of voice and communication style
    2. Clearly communicates the company's value proposition
    3. Resonates with the target market
    4. Maintains professionalism while being engaging
    """
    
    messages = [
        {"role": "system", "content": "You are an expert email copywriter."},
        {"role": "user", "content": enhanced_prompt}
    ]
    
    response = openai_chat_completion(messages)
    
    if not response:
        return current_template or prompt
        
    return response

def fetch_leads_with_sources(session):
    try:
        query = session.query(Lead, func.string_agg(LeadSource.url, ', ').label('sources'), func.max(EmailCampaign.sent_at).label('last_contact'), func.string_agg(EmailCampaign.status, ', ').label('email_statuses')).outerjoin(LeadSource).outerjoin(EmailCampaign).group_by(Lead.id)
        return pd.DataFrame([{**{k: getattr(lead, k) for k in ['id', 'email', 'first_name', 'last_name', 'company', 'job_title', 'created_at']}, 'Source': sources, 'Last Contact': last_contact, 'Last Email Status': email_statuses.split(', ')[-1] if email_statuses else 'Not Contacted', 'Delete': False} for lead, sources, last_contact, email_statuses in query.all()])
    except SQLAlchemyError as e:
        logging.error(f"Database error in fetch_leads_with_sources: {str(e)}")
        return pd.DataFrame()

def fetch_search_terms_with_lead_count(session):
    """Fetch search terms with their lead counts"""
    subquery = session.query(
        LeadSource.search_term_id,
        func.count('*').label('lead_count')
    ).group_by(LeadSource.search_term_id).subquery()
    
    return session.query(
        SearchTerm,
        subquery.c.lead_count
    ).outerjoin(
        subquery,
        SearchTerm.id == subquery.c.search_term_id
    ).all()

def add_search_term(session, term, campaign_id):
    """Add a new search term to the database"""
    new_term = SearchTerm(term=term, campaign_id=campaign_id)
    session.add(new_term)
    session.commit()

def get_active_campaign_id():
    """Get the ID of the currently active campaign"""
    return st.session_state.get('active_campaign_id')

def create_search_term_group(session, name):
    """Create a new search term group"""
    group = SearchTermGroup(name=name)
    session.add(group)
    session.commit()

def update_search_term_group(session, group_id, term_ids):
    """Update the terms in a search term group"""
    group = session.query(SearchTermGroup).get(group_id)
    if group:
        # Clear existing terms
        group.search_terms = []
        # Add selected terms
        term_ids = [int(t.split(':')[0]) for t in term_ids]
        terms = session.query(SearchTerm).filter(SearchTerm.id.in_(term_ids)).all()
        group.search_terms.extend(terms)
        session.commit()

def delete_search_term_group(session, group_id):
    """Delete a search term group"""
    try:
        group = session.query(SearchTermGroup).get(group_id)
        if group:
            session.delete(group)
            session.commit()
    except Exception as e:
        session.rollback()
        logging.error(f"Error deleting search term group: {str(e)}")

def ai_group_search_terms(session, ungrouped_terms):
    existing_groups = session.query(SearchTermGroup).all()
    prompt = f"Categorize these search terms into existing groups or suggest new ones:\n{', '.join([term.term for term in ungrouped_terms])}\n\nExisting groups: {', '.join([group.name for group in existing_groups])}\n\nRespond with a JSON object: {{group_name: [term1, term2, ...]}}"
    messages = [{"role": "system", "content": "You're an AI that categorizes search terms for lead generation. Be concise and efficient."}, {"role": "user", "content": prompt}]
    response = openai_chat_completion(messages, function_name="ai_group_search_terms")
    return response if isinstance(response, dict) else {}

def update_search_term_groups(session, grouped_terms):
    for group_name, terms in grouped_terms.items():
        group = session.query(SearchTermGroup).filter_by(name=group_name).first() or SearchTermGroup(name=group_name)
        if not group.id: session.add(group); session.flush()
        for term in terms:
            search_term = session.query(SearchTerm).filter_by(term=term).first()
            if search_term: search_term.group_id = group.id
    session.commit()

def delete_search_term_group(session, group_id):
    try:
        group = session.query(SearchTermGroup).get(group_id)
        if group:
            session.query(SearchTerm).filter(SearchTerm.group_id == group_id).update({SearchTerm.group_id: None})
            session.delete(group)
            session.commit()
    except Exception as e:
        session.rollback()
        logging.error(f"Error deleting search term group: {str(e)}")

def ai_automation_loop(session, log_container, leads_container):
    """AI automation loop with progress tracking and error handling"""
    automation_logs, total_search_terms, total_emails_sent = [], 0, 0
    while st.session_state.get('automation_status', False):
        try:
            log_container.info("Starting automation cycle")
            kb_info = get_knowledge_base_info(session, get_active_project_id())
            if not kb_info:
                log_container.warning("Knowledge Base not found. Skipping cycle.")
                time.sleep(3600)
                continue

            active_campaign_id = get_active_campaign_id()
            base_terms = [term.term for term in session.query(SearchTerm).filter_by(campaign_id=active_campaign_id).all()]
            optimized_terms = generate_optimized_search_terms(session, base_terms, kb_info)
            
            total_search_terms = len(optimized_terms)
            progress_bar = st.progress(0)
            
            for idx, term in enumerate(optimized_terms):
                results = manual_search(session, [term], 10, ignore_previously_fetched=True)
                new_leads = []
                for res in results['results']:
                    lead = save_lead(session, res['Email'], url=res['URL'])
                    if lead:
                        new_leads.append((lead.id, lead.email))
                
                if new_leads:
                    template = session.query(EmailTemplate).filter_by(project_id=get_active_project_id()).first()
                    if template:
                        from_email = kb_info.get('contact_email') or 'hello@indosy.com'
                        reply_to = kb_info.get('contact_email') or 'eugproductions@gmail.com'
                        logs, sent_count = bulk_send_emails(session, template.id, from_email, reply_to, 
                                                          [{'Email': email} for _, email in new_leads])
                        automation_logs.extend(logs)
                        total_emails_sent += sent_count
                
                leads_container.text_area("New Leads Found", "\n".join([email for _, email in new_leads]), height=200)
                progress_bar.progress((idx + 1) / len(optimized_terms))
            
            st.success(f"Automation cycle completed. Total search terms: {total_search_terms}, Total emails sent: {total_emails_sent}")
            time.sleep(3600)
        except Exception as e:
            log_container.error(f"Critical error in automation cycle: {str(e)}")
            time.sleep(300)
    
    log_container.info("Automation stopped")
    st.session_state.automation_logs = automation_logs
    st.session_state.total_leads_found = total_search_terms
    st.session_state.total_emails_sent = total_emails_sent

def openai_chat_completion(messages, temperature=0.7, function_name=None, lead_id=None, email_campaign_id=None):
    with db_session() as session:
        general_settings = session.query(Settings).filter_by(setting_type='general').first()
        if not general_settings or 'openai_api_key' not in general_settings.value:
            st.error("OpenAI API key not set. Please configure it in the settings.")
            return None

        client = OpenAI(api_key=general_settings.value['openai_api_key'])
        model = general_settings.value.get('openai_model', "gpt-4o-mini")

    try:
        response = client.chat.completions.create(
            model=model,
            messages=messages,
            temperature=temperature
        )
        result = response.choices[0].message.content
        with db_session() as session:
            log_ai_request(session, function_name, messages, result, lead_id, email_campaign_id, model)
        
        try:
            return json.loads(result)
        except json.JSONDecodeError:
            return result
    except Exception as e:
        st.error(f"Error in OpenAI API call: {str(e)}")
        with db_session() as session:
            log_ai_request(session, function_name, messages, str(e), lead_id, email_campaign_id, model)
        return None

def log_ai_request(session, function_name, prompt, response, lead_id=None, email_campaign_id=None, model_used=None):
    session.add(AIRequestLog(
        function_name=function_name,
        prompt=json.dumps(prompt),
        response=json.dumps(response) if response else None,
        lead_id=lead_id,
        email_campaign_id=email_campaign_id,
        model_used=model_used
    ))
    session.commit()

def save_lead(session, email, first_name=None, last_name=None, company=None, job_title=None, phone=None, url=None, search_term_id=None, created_at=None):
    try:
        existing_lead = session.query(Lead).filter_by(email=email).first()
        if existing_lead:
            for attr in ['first_name', 'last_name', 'company', 'job_title', 'phone', 'created_at']:
                if locals()[attr]: setattr(existing_lead, attr, locals()[attr])
            lead = existing_lead
        else:
            lead = Lead(email=email, first_name=first_name, last_name=last_name, company=company, job_title=job_title, phone=phone, created_at=created_at or datetime.utcnow())
            session.add(lead)
        session.flush()
        lead_source = LeadSource(lead_id=lead.id, url=url, search_term_id=search_term_id)
        session.add(lead_source)
        campaign_lead = CampaignLead(campaign_id=get_active_campaign_id(), lead_id=lead.id, status="Not Contacted", created_at=datetime.utcnow())
        session.add(campaign_lead)
        session.commit()
        return lead
    except Exception as e:
        logging.error(f"Error saving lead: {str(e)}")
        session.rollback()
        return None

def save_lead_source(session, lead_id, search_term_id, url, http_status, scrape_duration, page_title=None, meta_description=None, content=None, tags=None, phone_numbers=None):
    session.add(LeadSource(lead_id=lead_id, search_term_id=search_term_id, url=url, http_status=http_status, scrape_duration=scrape_duration, page_title=page_title or get_page_title(url), meta_description=meta_description or get_page_description(url), content=content or extract_visible_text(BeautifulSoup(requests.get(url).text, 'html.parser')), tags=tags, phone_numbers=phone_numbers))
    session.commit()

def get_page_title(url):
    try:
        response = requests.get(url, timeout=10)
        soup = BeautifulSoup(response.text, 'html.parser')
        title = soup.title.string if soup.title else "No title found"
        return title.strip()
    except Exception as e:
        logging.error(f"Error getting page title for {url}: {str(e)}")
        return "Error fetching title"

def extract_visible_text(soup):
    for script in soup(["script", "style"]):
        script.extract()
    text = soup.get_text()
    lines = (line.strip() for line in text.splitlines())
    chunks = (phrase.strip() for line in lines for phrase in line.split("  "))
    return ' '.join(chunk for chunk in chunks if chunk)

def log_search_term_effectiveness(session, term, total_results, valid_leads, blogs_found, directories_found):
    session.add(SearchTermEffectiveness(term=term, total_results=total_results, valid_leads=valid_leads, irrelevant_leads=total_results - valid_leads, blogs_found=blogs_found, directories_found=directories_found))
    session.commit()

get_active_project_id = lambda: st.session_state.get('active_project_id', 1)
get_active_campaign_id = lambda: st.session_state.get('active_campaign_id', 1)
set_active_project_id = lambda project_id: st.session_state.__setitem__('active_project_id', project_id)
set_active_campaign_id = lambda campaign_id: st.session_state.__setitem__('active_campaign_id', campaign_id)

def add_or_get_search_term(session, term, campaign_id, created_at=None):
    search_term = session.query(SearchTerm).filter_by(term=term, campaign_id=campaign_id).first()
    if not search_term:
        search_term = SearchTerm(term=term, campaign_id=campaign_id, created_at=created_at or datetime.utcnow())
        session.add(search_term)
        session.commit()
        session.refresh(search_term)
    return search_term.id

def fetch_campaigns(session):
    return [f"{camp.id}: {camp.campaign_name}" for camp in session.query(Campaign).all()]

def fetch_projects(session):
    return [f"{project.id}: {project.project_name}" for project in session.query(Project).all()]

def fetch_email_templates(session):
    return [f"{t.id}: {t.template_name}" for t in session.query(EmailTemplate).all()]
def create_or_update_email_template(session, template_name, subject, body_content, template_id=None, is_ai_customizable=False, created_at=None, language='ES'):
    try:
        if template_id:
            template = session.query(EmailTemplate).filter_by(id=template_id).first()
            if template:
                template.template_name = template_name
                template.subject = subject 
                template.body_content = body_content
                template.is_ai_customizable = is_ai_customizable
                template.language = language
            else:
                return None
        else:
            template = EmailTemplate(
                template_name=template_name,
                subject=subject,
                body_content=body_content, 
                is_ai_customizable=is_ai_customizable,
                campaign_id=get_active_campaign_id(),
                created_at=created_at or datetime.utcnow(),
                language=language
            )
            session.add(template)
            
        session.commit()
        return template.id
    except SQLAlchemyError as e:
        logging.error(f"Error creating/updating email template: {str(e)}")
        session.rollback()
        return None

def safe_datetime_compare(date1, date2):
    if date1 is None or date2 is None:
        return False
    return date1 > date2

def fetch_leads(session, template_id, send_option, specific_email, selected_terms, exclude_previously_contacted):
    """Fetch leads based on criteria"""
    query = session.query(Lead)
    if specific_email:
        query = query.filter(Lead.email == specific_email)
    if selected_terms:
        query = query.join(LeadSource).filter(LeadSource.search_term_id.in_(selected_terms))
        if exclude_previously_contacted:
            contacted_leads = session.query(EmailCampaign.lead_id).filter(EmailCampaign.template_id == template_id)
            query = query.filter(~Lead.id.in_(contacted_leads))
    return query.all()

def update_display(container, items, title, item_key=None, display_type='default'):
    """Update display with items"""
    if not items:
        container.warning(f"No {title} found.")
        return
    
    if display_type == 'table':
        container.table(items)
    else:
        for item in items:
            display_text = item[item_key] if item_key else str(item)
            container.text(display_text)

def manual_search_page():
    """Manual search page implementation"""
    st.title("Manual Search")
    # Implementation details...

def fetch_email_settings(session):
    """Fetch email settings"""
    return session.query(EmailSettings).all()

def bulk_send_emails(session, template_id, from_email, reply_to, leads, progress_bar=None, status_text=None, results=None, log_container=None):
    """Send bulk emails"""
    # Implementation details...
    pass

def generate_optimized_search_terms(session, base_terms, kb_info):
    """Generate optimized search terms"""
    if not base_terms:
        return []  # Return empty list if no base terms found
    prompt = f"Optimize and expand these search terms for lead generation:\n{', '.join(base_terms)}\n\nConsider:\n1. Relevance to business and target market\n2. Potential for high-quality leads\n3. Variations and related terms\n4. Industry-specific jargon\n\nRespond with a JSON array of optimized terms."
    response = openai_chat_completion([{"role": "system", "content": "You're an AI specializing in optimizing search terms for lead generation. Be concise and effective."}, {"role": "user", "content": prompt}], function_name="generate_optimized_search_terms")
    if isinstance(response, dict) and 'optimized_terms' in response:
        return response['optimized_terms']
    return base_terms  # Return original terms if optimization fails

def get_knowledge_base_info(session, project_id):
    """Get knowledge base info for a project"""
    return session.query(KnowledgeBase).filter(KnowledgeBase.project_id == project_id).first()

def fetch_leads_for_search_terms(session, search_term_ids) -> List['Leads']:
    """Fetch leads for the given search term IDs."""
    leads = session.query(Leads).join(LeadSources).filter(
        LeadSources.search_term_id.in_(search_term_ids)
    ).all()
    return leads

def projects_campaigns_page():
    st.title("Projects & Campaigns")
    
    with db_session() as session:
        project_options = fetch_projects(session)
        if not project_options: return st.warning("No projects found. Please create a project first.")
        selected_project = st.selectbox("Select Project", options=project_options)
        project_id = int(selected_project.split(":")[0])
        set_active_project_id(project_id)
        
        # Campaign selection - now filtered by project_id
        campaigns = session.query(Campaign).filter_by(project_id=project_id).all()
        campaign_names = [c.campaign_name for c in campaigns]
        
        if campaign_names:
            active_campaign = st.selectbox(
                "Select Campaign",
                options=campaign_names,
                key="active_campaign"
            )
            
            # Get active campaign using both project_id and campaign_name
            active_campaign = session.query(Campaign)\
                .filter_by(campaign_name=active_campaign, project_id=project_id)\
                .order_by(Campaign.created_at.desc())\
                .first()
                
            if active_campaign:
                st.session_state.active_campaign_id = active_campaign.id
            else:
                st.session_state.active_campaign_id = None
        else:
            st.warning("No campaigns found for this project. Please create a campaign first.")
            st.session_state.active_campaign_id = None

        # Display campaign details if one is selected
        if st.session_state.active_campaign_id:
            campaign = session.query(Campaign).get(st.session_state.active_campaign_id)
            if campaign:
                col1, col2 = st.columns(2)
                with col1:
                    st.subheader("Campaign Details")
                    st.write(f"Name: {campaign.campaign_name}")
                    st.write(f"Type: {campaign.campaign_type}")
                    st.write(f"Created: {campaign.created_at}")
                    
                    # Display campaign metrics
                    metrics = get_campaign_effectiveness(session, campaign.id)
                    if metrics:
                        st.subheader("Campaign Metrics")
                        st.metric("Emails Sent", metrics["total_sent"])
                        st.metric("Open Rate", f"{metrics['open_rate']:.1f}%")
                        st.metric("Click Rate", f"{metrics['click_rate']:.1f}%")
                    
                with col2:
                    st.subheader("Campaign Settings")
                    auto_send = st.checkbox("Auto Send", value=campaign.auto_send)
                    loop_automation = st.checkbox("Loop Automation", value=campaign.loop_automation)
                    ai_customization = st.checkbox("AI Customization", value=campaign.ai_customization)
                    max_emails = st.number_input("Max Emails per Group", 
                                               value=campaign.max_emails_per_group,
                                               min_value=1)
                    
                    if st.button("Update Settings"):
                        campaign.auto_send = auto_send
                        campaign.loop_automation = loop_automation
                        campaign.ai_customization = ai_customization
                        campaign.max_emails_per_group = max_emails
                        session.commit()
                        st.success("Campaign settings updated!")
                        
                # Display campaign leads with scores
                st.subheader("Campaign Leads")
                leads = fetch_leads_for_search_terms(session, [st.id for st in campaign.search_terms])
                if leads:
                    update_lead_scores(session)
                    lead_data = []
                    for lead in leads:
                        lead_data.append({
                            "Email": lead.email,
                            "Company": lead.company or "",
                            "Job Title": lead.job_title or "",
                            "Lead Score": lead.lead_score or 0,
                            "Status": lead.status or "New"
                        })
                    
                    if lead_data:
                        df = pd.DataFrame(lead_data)
                        st.dataframe(df.sort_values("Lead Score", ascending=False))
                else:
                    st.info("No leads found for this campaign")

def knowledge_base_page():
    st.title("Knowledge Base")
    with db_session() as session:
        project_options = fetch_projects(session)
        if not project_options: return st.warning("No projects found. Please create a project first.")
        selected_project = st.selectbox("Select Project", options=project_options)
        project_id = int(selected_project.split(":")[0])
        set_active_project_id(project_id)
        kb_entry = session.query(KnowledgeBase).filter_by(project_id=project_id).first()
        with st.form("knowledge_base_form"):
            fields = ['kb_name', 'kb_bio', 'kb_values', 'contact_name', 'contact_role', 'contact_email', 'company_description', 'company_mission', 'company_target_market', 'company_other', 'product_name', 'product_description', 'product_target_customer', 'product_other', 'other_context', 'example_email']
            form_data = {field: st.text_input(field.replace('_', ' ').title(), value=getattr(kb_entry, field, '')) if field in ['kb_name', 'contact_name', 'contact_role', 'contact_email', 'product_name'] else st.text_area(field.replace('_', ' ').title(), value=getattr(kb_entry, field, '')) for field in fields}
            if st.form_submit_button("Save Knowledge Base"):
                try:
                    form_data.update({'project_id': project_id, 'created_at': datetime.utcnow()})
                    if kb_entry:
                        for k, v in form_data.items(): setattr(kb_entry, k, v)
                    else: session.add(KnowledgeBase(**form_data))
                    session.commit()
                    st.success("Knowledge Base saved successfully!", icon="✅")
                except Exception as e: st.error(f"An error occurred while saving the Knowledge Base: {str(e)}")

def autoclient_ai_page():
    st.header("AutoclientAI - Automated Lead Generation")
    with st.expander("Knowledge Base Information", expanded=False):
        with db_session() as session:
            kb_info = get_knowledge_base_info(session, get_active_project_id())
        if not kb_info:
            return st.error("Knowledge Base not found for the active project. Please set it up first.")
        st.json(kb_info)
    user_input = st.text_area("Enter additional context or specific goals for lead generation:", help="This information will be used to generate more targeted search terms.")
    if st.button("Generate Optimized Search Terms", key="generate_optimized_terms"):
        with st.spinner("Generating optimized search terms..."):
            with db_session() as session:
                base_terms = [term.term for term in session.query(SearchTerm).filter_by(project_id=get_active_project_id()).all()]
                optimized_terms = generate_optimized_search_terms(session, base_terms, kb_info)
            if optimized_terms:
                st.session_state.optimized_terms = optimized_terms
                st.success("Search terms optimized successfully!")
                st.subheader("Optimized Search Terms")
                st.write(", ".join(optimized_terms))
            else:
                st.error("Failed to generate optimized search terms. Please try again.")
    if st.button("Start Automation", key="start_automation"):
        st.session_state.update({"automation_status": True, "automation_logs": [], "total_leads_found": 0, "total_emails_sent": 0})
        st.success("Automation started!")
    if st.session_state.get('automation_status', False):
        st.subheader("Automation in Progress")
        progress_bar, log_container, leads_container, analytics_container = st.progress(0), st.empty(), st.empty(), st.empty()
        try:
            with db_session() as session:
                ai_automation_loop(session, log_container, leads_container)
        except Exception as e:
            st.error(f"An error occurred in the automation process: {str(e)}")
            st.session_state.automation_status = False
    if not st.session_state.get('automation_status', False) and st.session_state.get('automation_logs'):
        st.subheader("Automation Results")
        st.metric("Total Leads Found", st.session_state.total_leads_found)
        st.metric("Total Emails Sent", st.session_state.total_emails_sent)
        st.subheader("Automation Logs")
        st.text_area("Logs", "\n".join(st.session_state.automation_logs), height=300)
    if 'email_logs' in st.session_state:
        st.subheader("Email Sending Logs")
        df_logs = pd.DataFrame(st.session_state.email_logs)
        st.dataframe(df_logs)
        success_rate = (df_logs['Status'] == 'sent').mean() * 100
        st.metric("Email Sending Success Rate", f"{success_rate:.2f}%")
    st.subheader("Debug Information")
    st.json(st.session_state)
    st.write("Current function:", autoclient_ai_page.__name__)
    st.write("Session state keys:", list(st.session_state.keys()))

def update_search_terms(session, classified_terms):
    for group, terms in classified_terms.items():
        for term in terms:
            existing_term = session.query(SearchTerm).filter_by(term=term, project_id=get_active_project_id()).first()
            if existing_term:
                existing_term.group = group
            else:
                session.add(SearchTerm(term=term, group=group, project_id=get_active_project_id()))
    session.commit()

def update_results_display(results_container, results):
    results_container.markdown(
        f"""
        <style>
        .results-container {{
            max-height: 400px;
            overflow-y: auto;
            border: 1px solid rgba(49, 51, 63, 0.2);
            border-radius: 0.25rem;
            padding: 1rem;
            background-color: rgba(49, 51, 63, 0.1);
        }}
        .result-entry {{
            margin-bottom: 0.5rem;
            padding: 0.5rem;
            background-color: rgba(255, 255, 255, 0.1);
            border-radius: 0.25rem;
        }}
        </style>
        <div class="results-container">
            <h4>Found Leads ({len(results)})</h4>
            {"".join(f'<div class="result-entry"><strong>{res["Email"]}</strong><br>{res["URL"]}</div>' for res in results[-10:])}
        </div>
        """,
        unsafe_allow_html=True
    )

def automation_control_panel_page():
    st.title("Automation Control Panel")

    col1, col2 = st.columns([2, 1])
    with col1:
        status = "Active" if st.session_state.get('automation_status', False) else "Inactive"
        st.metric("Automation Status", status)
    with col2:
        button_text = "Stop Automation" if st.session_state.get('automation_status', False) else "Start Automation"
        if st.button(button_text, use_container_width=True):
            st.session_state.automation_status = not st.session_state.get('automation_status', False)
            if st.session_state.automation_status:
                st.session_state.automation_logs = []
            st.rerun()

    if st.button("Perform Quick Scan", use_container_width=True):
        with st.spinner("Performing quick scan..."):
            try:
                with db_session() as session:
                    new_leads = session.query(Lead).filter(Lead.is_processed == False).count()
                    session.query(Lead).filter(Lead.is_processed == False).update({Lead.is_processed: True})
                    session.commit()
                    st.success(f"Quick scan completed! Found {new_leads} new leads.")
            except Exception as e:
                st.error(f"An error occurred during quick scan: {str(e)}")

    st.subheader("Real-Time Analytics")
    try:
        with db_session() as session:
            total_leads = session.query(Lead).count()
            emails_sent = session.query(EmailCampaign).count()
            col1, col2 = st.columns(2)
            col1.metric("Total Leads", total_leads)
            col2.metric("Emails Sent", emails_sent)
    except Exception as e:
        st.error(f"An error occurred while displaying analytics: {str(e)}")

    st.subheader("Automation Logs")
    log_container = st.empty()
    update_display(log_container, st.session_state.get('automation_logs', []), "Latest Logs", "log")

    st.subheader("Recently Found Leads")
    leads_container = st.empty()

    if st.session_state.get('automation_status', False):
        st.info("Automation is currently running in the background.")
        try:
            with db_session() as session:
                while st.session_state.get('automation_status', False):
                    kb_info = get_knowledge_base_info(session, get_active_project_id())
                    if not kb_info:
                        st.session_state.automation_logs.append("Knowledge Base not found. Skipping cycle.")
                        time.sleep(3600)
                        continue

                    base_terms = [term.term for term in session.query(SearchTerm).filter_by(project_id=get_active_project_id()).all()]
                    if not base_terms:
                        st.session_state.automation_logs.append("No search terms found. Skipping cycle.")
                        time.sleep(3600)
                        continue

                    optimized_terms = generate_optimized_search_terms(session, base_terms, kb_info)
                    if not optimized_terms:
                        st.session_state.automation_logs.append("Failed to generate optimized terms. Skipping cycle.")
                        time.sleep(3600)
                        continue

                    new_leads_all = []
                    for term in optimized_terms:
                        try:
                            results = manual_search(session, [term], 10)
                            if results and 'results' in results:
                                new_leads = [(res['Email'], res['URL']) for res in results['results'] 
                                           if res.get('Email') and res.get('URL') and 
                                           save_lead(session, res['Email'], url=res['URL'])]
                                new_leads_all.extend(new_leads)
                                st.session_state.automation_logs.append(f"Found {len(new_leads)} leads for term: {term}")
                        except Exception as e:
                            st.session_state.automation_logs.append(f"Error searching term {term}: {str(e)}")
                            continue

                    if new_leads_all:
                        template = session.query(EmailTemplate).filter_by(project_id=get_active_project_id()).first()
                        if template:
                            from_email = kb_info.get('contact_email') or 'hello@indosy.com'
                            reply_to = kb_info.get('contact_email') or 'eugproductions@gmail.com'
                            try:
                                logs, sent_count = bulk_send_emails(session, template.id, from_email, reply_to, 
                                                                  [{'Email': email} for email, _ in new_leads_all])
                                st.session_state.automation_logs.extend(logs)
                            except Exception as e:
                                st.session_state.automation_logs.append(f"Error sending emails: {str(e)}")

                        leads_df = pd.DataFrame(new_leads_all, columns=['Email', 'URL'])
                        leads_container.dataframe(leads_df, hide_index=True)
                    else:
                        leads_container.info("No new leads found in this cycle.")

                    update_display(log_container, st.session_state.get('automation_logs', []), "Latest Logs", "log")
                    time.sleep(3600)

        except Exception as e:
            st.error(f"An error occurred in the automation process: {str(e)}")
            st.session_state.automation_status = False

def generate_optimized_search_terms(session, base_terms, kb_info):
    if not base_terms:
        return []  # Return empty list if no base terms found
    prompt = f"Optimize and expand these search terms for lead generation:\n{', '.join(base_terms)}\n\nConsider:\n1. Relevance to business and target market\n2. Potential for high-quality leads\n3. Variations and related terms\n4. Industry-specific jargon\n\nRespond with a JSON array of optimized terms."
    response = openai_chat_completion([{"role": "system", "content": "You're an AI specializing in optimizing search terms for lead generation. Be concise and effective."}, {"role": "user", "content": prompt}], function_name="generate_optimized_search_terms")
    if isinstance(response, dict) and 'optimized_terms' in response:
        return response['optimized_terms']
    return base_terms  # Return original terms if optimization fails

def update_display(container, items, title, item_type):
    container.markdown(f"<h4>{title}</h4>", unsafe_allow_html=True)
    for item in items[-10:]:
        container.text(item)

def get_search_terms(session):
    return [term.term for term in session.query(SearchTerm).filter_by(project_id=get_active_project_id()).all()]

def get_ai_response(prompt):
    """Get AI response using OpenAI API"""
    try:
        client = OpenAI()
        response = client.chat.completions.create(
            model="gpt-3.5-turbo",
            messages=[{"role": "user", "content": prompt}]
        )
        return response.choices[0].message.content
    except Exception as e:
        logging.error(f"Error getting AI response: {str(e)}")
        return None

def fetch_email_settings(session):
    try:
        settings = session.query(EmailSettings).all()
        return [{"id": setting.id, "name": setting.name, "email": setting.email} for setting in settings]
    except Exception as e:
        logging.error(f"Error fetching email settings: {e}")
        return []

def bulk_send_emails(session, template_id, from_email, reply_to, leads, progress_bar=None, status_text=None, results=None, log_container=None):
    """Enhanced bulk email sending with better error handling and rate limiting"""
    template = session.query(EmailTemplate).filter_by(id=template_id).first()
    if not template:
        logging.error(f"Email template with ID {template_id} not found.")
        return [], 0

    email_subject = template.subject
    email_content = template.body_content
    logs, sent_count = [], 0
    total_leads = len(leads)
    
    # Add rate limiting
    rate_limit = 50  # emails per minute
    delay = 60 / rate_limit

    for index, lead in enumerate(leads):
        try:
            if not is_valid_email(lead['Email']):
                raise EmailNotValidError("Invalid email format")

            # Add rate limiting delay
            time.sleep(delay)
                
            response, tracking_id = send_email_ses(
                session, from_email, lead['Email'], 
                email_subject, email_content, 
                reply_to=reply_to
            )
            
            if response:
                status = 'sent'
                message_id = response.get('MessageId', f"sent-{uuid.uuid4()}")
                sent_count += 1
                log_message = f"✅ Email sent to: {lead['Email']}"
            else:
                status = 'failed'
                message_id = f"failed-{uuid.uuid4()}"
                log_message = f"❌ Failed to send email to: {lead['Email']}"
            
            save_email_campaign(
                session, lead['Email'], template_id, 
                status, datetime.utcnow(), 
                email_subject, message_id, email_content
            )
            
            logs.append(log_message)
            
            # Update progress indicators
            if progress_bar:
                progress_bar.progress((index + 1) / total_leads)
            if status_text:
                status_text.text(f"Processed {index + 1}/{total_leads} leads")
            if results is not None:
                results.append({"Email": lead['Email'], "Status": status})
            if log_container:
                log_container.text(log_message)

        except EmailNotValidError:
            log_message = f"❌ Invalid email address: {lead['Email']}"
            logs.append(log_message)
            if log_container:
                log_container.text(log_message)
        except Exception as e:
            error_message = f"Error sending email to {lead['Email']}: {str(e)}"
            logging.error(error_message)
            save_email_campaign(
                session, lead['Email'], template_id, 
                'failed', datetime.utcnow(), 
                email_subject, f"error-{uuid.uuid4()}", 
                email_content
            )
            logs.append(f"❌ {error_message}")
            if log_container:
                log_container.text(error_message)

    return logs, sent_count

def wrap_email_body(body_content):
    return f"""
    <!DOCTYPE html>
    <html lang="en">
    <head>
        <meta charset="UTF-8">
        <meta name="viewport" content="width=device-width, initial-scale=1.0">
        <title>Email Template</title>
        <style>
            body {{
                font-family: Arial, sans-serif;
                line-height: 1.6;
                color: #333;
                max-width: 600px;
                margin: 0 auto;
                padding: 20px;
            }}
        </style>
    </head>
    <body>
        {body_content}
    </body>
    </html>
    """

def fetch_sent_email_campaigns(session):
    try:
        email_campaigns = session.query(EmailCampaign).join(Lead).join(EmailTemplate).options(joinedload(EmailCampaign.lead), joinedload(EmailCampaign.template)).order_by(EmailCampaign.sent_at.desc()).all()
        return pd.DataFrame({
            'ID': [ec.id for ec in email_campaigns],
            'Sent At': [ec.sent_at.strftime("%Y-%m-%d %H:%M:%S") if ec.sent_at else "" for ec in email_campaigns],
            'Email': [ec.lead.email for ec in email_campaigns],
            'Template': [ec.template.template_name for ec in email_campaigns],
            'Subject': [ec.customized_subject or "No subject" for ec in email_campaigns],
            'Content': [ec.customized_content or "No content" for ec in email_campaigns],
            'Status': [ec.status for ec in email_campaigns],
            'Message ID': [ec.message_id or "No message ID" for ec in email_campaigns],
            'Campaign ID': [ec.campaign_id for ec in email_campaigns],
            'Lead Name': [f"{ec.lead.first_name or ''} {ec.lead.last_name or ''}".strip() or "Unknown" for ec in email_campaigns],
            'Lead Company': [ec.lead.company or "Unknown" for ec in email_campaigns]
        })
    except SQLAlchemyError as e:
        logging.error(f"Database error in fetch_sent_email_campaigns: {str(e)}")
        return pd.DataFrame()

def display_logs(log_container, logs):
    if not logs:
        log_container.info("No logs to display yet.")
        return

    # Initialize session state for log tracking
    if 'last_log_count' not in st.session_state:
        st.session_state.last_log_count = 0
    
    # Check for new logs
    new_logs = len(logs) - st.session_state.last_log_count
    st.session_state.last_log_count = len(logs)

    log_container.markdown(
        f"""
        <style>
        .log-container {{
            max-height: 300px;
            overflow-y: auto;
            border: 1px solid rgba(49, 51, 63, 0.2);
            border-radius: 8px;
            padding: 1rem;
            background: linear-gradient(to bottom, #ffffff, #f8f9fa);
            box-shadow: 0 2px 4px rgba(0,0,0,0.05);
        }}
        .log-header {{
            display: flex;
            justify-content: space-between;
            align-items: center;
            margin-bottom: 10px;
            padding: 0 10px;
        }}
        .log-stats {{
            font-size: 0.9em;
            color: #666;
        }}
        .new-logs-badge {{
            background: #ff4b4b;
            color: white;
            padding: 2px 8px;
            border-radius: 12px;
            font-size: 0.8em;
            display: {new_logs > 0 and 'inline-block' or 'none'};
        }}
        .log-entry {{
            margin-bottom: 0.5rem;
            padding: 0.8rem;
            border-radius: 6px;
            background-color: rgba(28, 131, 225, 0.05);
            border-left: 3px solid #1c83e1;
            font-family: "SFMono-Regular", Consolas, monospace;
            transition: background-color 0.3s ease;
        }}
        .log-entry:hover {{
            background-color: rgba(28, 131, 225, 0.1);
        }}
        .log-entry.new {{
            animation: highlight 2s ease-out;
        }}
        @keyframes highlight {{
            0% {{ background-color: rgba(255, 75, 75, 0.2); }}
            100% {{ background-color: rgba(28, 131, 225, 0.05); }}
        }}
        </style>
        
        <div class="log-container">
            <div class="log-header">
                <div class="log-stats">
                    Total Logs: {len(logs)}
                    <span class="new-logs-badge">{new_logs} new</span>
                </div>
                <div class="log-timestamp">
                    Last Update: {datetime.now().strftime("%H:%M:%S")}
                </div>
            </div>
            {"".join(
                f'<div class="log-entry{" new" if i >= len(logs) - new_logs else ""}">{log}</div>' 
                for i, log in enumerate(logs[-20:])
            )}
        </div>
        
        <script>
            function setupLogContainer() {{
                const container = document.querySelector('.log-container');
                if (!container) return;
                
                // Auto-scroll to bottom
                container.scrollTop = container.scrollHeight;
                
                // Observe changes
                const observer = new MutationObserver(() => {{
                    container.scrollTop = container.scrollHeight;
                }});
                
                observer.observe(container, {{ childList: true, subtree: true }});
                
                // Remove 'new' class after animation
                setTimeout(() => {{
                    document.querySelectorAll('.log-entry.new').forEach(entry => {{
                        entry.classList.remove('new');
                    }});
                }}, 2000);
            }}
            
            // Run setup when content loads
            setupLogContainer();
            
            // Rerun setup when Streamlit updates
            if (window.streamlitRerun) {{
                const originalRerun = window.streamlitRerun;
                window.streamlitRerun = (...args) => {{
                    originalRerun(...args);
                    setupLogContainer();
                }};
            }}
        </script>
        """,
        unsafe_allow_html=True
    )

def view_sent_email_campaigns():
    st.header("Sent Email Campaigns")
    try:
        with db_session() as session:
            email_campaigns = fetch_sent_email_campaigns(session)
        if not email_campaigns.empty:
            st.dataframe(email_campaigns)
            st.subheader("Detailed Content")
            selected_campaign = st.selectbox("Select a campaign to view details", email_campaigns['ID'].tolist())
            if selected_campaign:
                campaign_content = email_campaigns[email_campaigns['ID'] == selected_campaign]['Content'].iloc[0]
                st.text_area("Content", campaign_content if campaign_content else "No content available", height=300)
        else:
            st.info("No sent email campaigns found.")
    except Exception as e:
        st.error(f"An error occurred while fetching sent email campaigns: {str(e)}")
        logging.error(f"Error in view_sent_email_campaigns: {str(e)}")

# --- Add these global variables ---
SEARCH_PROCESS = None
MESSAGE_QUEUE = multiprocessing.Queue()

# --- Add this function to start the background process ---
def start_background_process():
    global SEARCH_PROCESS, MESSAGE_QUEUE
    
    # Initialize process manager and logging
    process_manager = ProcessManager()
    log_handler = AutomationLogHandler()
    
    # Check and cleanup existing process
    if SEARCH_PROCESS and SEARCH_PROCESS.is_alive():
        try:
            log_handler.log("Stopping existing search process")
            process_manager.stop_process(SEARCH_PROCESS.pid)
            MESSAGE_QUEUE.put("STOP")
            SEARCH_PROCESS.join(timeout=5)
            SEARCH_PROCESS.terminate()
        except Exception as e:
            log_handler.log(f"Error stopping process: {str(e)}")
            
    # Add resource limits
    import resource
    resource.setrlimit(resource.RLIMIT_CPU, (3600, 3600))  # 1 hour CPU time limit
    resource.setrlimit(resource.RLIMIT_AS, (1024 * 1024 * 1024, 1024 * 1024 * 1024))  # 1GB memory limit
    
    # Initialize new process with persistence
    MESSAGE_QUEUE = multiprocessing.Queue()
    SEARCH_PROCESS = Process(target=background_search_worker, args=(MESSAGE_QUEUE,))
    SEARCH_PROCESS.daemon = False  # Allow process to continue after main process exits
    SEARCH_PROCESS.start()
    
    # Register process with manager and persist state
    process_manager.register_process(SEARCH_PROCESS.pid, "search_process")
    st.session_state.background_process_started = True
    log_handler.log(f"Started search process with PID: {SEARCH_PROCESS.pid}")

# --- Add this function to stop the background process ---
def stop_background_process():
    global SEARCH_PROCESS, MESSAGE_QUEUE
    
    log_handler = AutomationLogHandler()
    process_manager = ProcessManager()
    
    try:
        if SEARCH_PROCESS and SEARCH_PROCESS.is_alive():
            log_handler.log("Stopping search process")
            process_manager.stop_process(SEARCH_PROCESS.pid)
            MESSAGE_QUEUE.put("STOP")
            SEARCH_PROCESS.join(timeout=5)
            SEARCH_PROCESS.terminate()
            
        st.session_state.background_process_started = False
        log_handler.log("Search process stopped successfully")
    except Exception as e:
        log_handler.log(f"Error stopping process: {str(e)}")

# --- Add this function to handle background search ---
def background_search_worker(message_queue):
    while True:
        try:
            if message_queue.empty():
                time.sleep(0.1)
                continue
                
            msg = message_queue.get()
            if msg == "STOP":
                break
                
            if isinstance(msg, dict) and msg.get('type') == 'search':
                query = msg['query']
                try:
                    # Perform search with progress updates
                    results = perform_search_with_progress(query, message_queue)
                    message_queue.put({
                        'type': 'result',
                        'results': results
                    })
                except Exception as e:
                    message_queue.put({
                        'type': 'error',
                        'error': str(e)
                    })
                    
        except Exception as e:
            try:
                message_queue.put({
                    'type': 'error',
                    'error': f"Background worker error: {str(e)}"
                })
            except:
                # Replace pass with proper error logging
                logging.error(f"Failed to send error message: {str(e)}")

def perform_search_with_progress(query, message_queue):
    try:
        # Initialize progress
        message_queue.put({
            'type': 'progress',
            'value': 0,
            'status': 'Starting search...'
        })
        
        # Your existing search logic here, with progress updates
        # Example:
        results = []
        total_steps = 5  # Adjust based on your actual search steps
        
        for i in range(total_steps):
            # Perform search step
            # Add results to results list
            
            # Update progress
            progress = (i + 1) / total_steps
            message_queue.put({
                'type': 'progress',
                'value': progress,
                'status': f'Processing step {i + 1} of {total_steps}...'
            })
            
            time.sleep(0.5)  # Simulate work
            
        return results
        
    except Exception as e:
        raise Exception(f"Search error: {str(e)}")

# --- Modify manual_search_page to use the background process ---
def manual_search_page():
    """Enhanced manual search page with better error handling and progress tracking"""
    st.title("Manual Search")
    
    with st.form("manual_search_form"):
        search_terms = st_tags(
            label='Enter Search Terms:',
            text='Press enter to add more',
            value=st.session_state.get('search_terms', []),
            key='manual_search_terms'
        )
        
        col1, col2 = st.columns(2)
        with col1:
            num_results = st.number_input("Number of results per term", 1, 100, 10)
            ignore_fetched = st.checkbox("Ignore previously fetched URLs", True)
        with col2:
            optimize_english = st.checkbox("Optimize for English", False)
            optimize_spanish = st.checkbox("Optimize for Spanish", True)
            shuffle_keywords_option = st.checkbox("Shuffle Keywords", False)
        
        submitted = st.form_submit_button("Start Search")
        
    if submitted and search_terms:
        try:
            with st.spinner("Searching..."):
                process_id = str(uuid.uuid4())
                settings = {
                    'num_results': num_results,
                    'ignore_fetched': ignore_fetched,
                    'optimize_english': optimize_english,
                    'optimize_spanish': optimize_spanish,
                    'shuffle_keywords': shuffle_keywords_option
                }
                
                st.session_state.process_manager.start_process(
                    process_id,
                    background_manual_search,
                    (process_id, search_terms, settings)
                )
                
                st.success("Search process started! Check the Process Monitor for results.")
                
        except Exception as e:
            st.error(f"Error starting search: {str(e)}")
            logging.error(f"Search error: {str(e)}")

# --- Navigation function ---
def navigate_to(page):
    st.session_state.current_page = page

def initialize_session_state():
    """Initialize session state variables."""
    if 'active_page' not in st.session_state:
        st.session_state.active_page = 'Manual Search'
    if 'search_results' not in st.session_state:
        st.session_state.search_results = []
    if 'current_project_id' not in st.session_state:
        st.session_state.current_project_id = None
    if 'current_campaign_id' not in st.session_state:
        st.session_state.current_campaign_id = None
    if 'edit_template_id' not in st.session_state:
        st.session_state.edit_template_id = None
    if 'search_terms' not in st.session_state:
        st.session_state.search_terms = []
    if 'search_term_groups' not in st.session_state:
        st.session_state.search_term_groups = []
    if 'background_processes' not in st.session_state:
        st.session_state.background_processes = {}
    if 'process_logs' not in st.session_state:
        st.session_state.process_logs = {}
    if 'automation_status' not in st.session_state:
        st.session_state.automation_status = 'stopped'
    if 'process_manager' not in st.session_state:
        st.session_state.process_manager = ProcessManager()
    if 'initialized' not in st.session_state:
        st.session_state.initialized = True

def main():
    initialize_session_state()
    
    # Set up page config
    st.set_page_config(
        page_title="Email Lead Generator",
        page_icon="🔍",
        layout="wide",
        initial_sidebar_state="expanded"
    )

    # Navigation menu
    with st.sidebar:
        selected = option_menu(
            "Navigation",
            ["Manual Search", "Search Terms", "Email Templates", "Bulk Send", 
             "View Leads", "Campaign Logs", "Sent Emails", "Projects & Campaigns",
             "Knowledge Base", "AutoClient AI", "Automation Control"],
            icons=['search', 'list-task', 'envelope', 'send', 'person-lines-fill',
                  'journal-text', 'envelope-open', 'folder', 'book',
                  'robot', 'gear'],
            menu_icon="cast",
            default_index=0
        )
        st.session_state.active_page = selected

    # Page routing
    if selected == "Manual Search":
        manual_search_page()
    elif selected == "Search Terms":
        search_terms_page()
    elif selected == "Email Templates":
        email_templates_page()
    elif selected == "Bulk Send":
        bulk_send_page()
    elif selected == "View Leads":
        view_leads_page()
    elif selected == "Campaign Logs":
        view_campaign_logs()
    elif selected == "Sent Emails":
        view_sent_email_campaigns()
    elif selected == "Projects & Campaigns":
        projects_campaigns_page()
    elif selected == "Knowledge Base":
        knowledge_base_page()
    elif selected == "AutoClient AI":
        autoclient_ai_page()
    elif selected == "Automation Control":
        automation_control_panel_page()

def search_terms_page():
    st.title("Search Terms Management")
    
    with db_session() as session:
        # Fetch existing search terms and groups
        search_terms = fetch_search_terms_with_lead_count(session)
        groups = session.query(SearchTermGroup).all()
        
        # Create tabs for different functionalities
        tab1, tab2, tab3, tab4, tab5 = st.tabs([
            "View Search Terms", 
            "Add Search Term", 
            "Manage Groups",
            "AI Grouping",
            "Group Settings"
        ])
        
        with tab1:
            st.subheader("Existing Search Terms")
            if search_terms:
                df = pd.DataFrame([{
                    'ID': term.id,
                    'Term': term.term,
                    'Group': term.group.name if term.group else 'None',
                    'Lead Count': term.lead_count if hasattr(term, 'lead_count') else 0,
                    'Created': term.created_at
                } for term in search_terms])
                
                st.dataframe(df)
            else:
                st.info("No search terms found.")
                
        with tab2:
            st.subheader("Add New Search Term")
            new_term = st.text_input("Enter new search term")
            campaign_id = get_active_campaign_id()
            
            group_options = ["None"] + [f"{g.id}: {g.name}" for g in groups]
            group_for_new_term = st.selectbox(
                "Select group for new term",
                options=group_options,
                format_func=lambda x: x.split(":")[1] if ":" in x else x
            )
            
            if st.button("Add Term") and new_term:
                add_new_search_term(session, new_term, campaign_id)
                st.success(f"Added new search term: {new_term}")
                st.rerun()
                
        with tab3:
            st.subheader("Manage Term Groups")
            if groups:
                for group in groups:
                    with st.expander(f"Group: {group.name}"):
                        group_terms = [
                            f"{term.id}: {term.term}" 
                            for term in search_terms 
                            if term.group_id == group.id
                        ]
                        available_terms = [
                            f"{term.id}: {term.term}" 
                            for term in search_terms 
                            if not term.group_id or term.group_id != group.id
                        ]
                        
                        selected_terms = st.multiselect(
                            "Select terms for this group",
                            options=available_terms + group_terms,
                            default=group_terms,
                            key=f"group_{group.id}"
                        )
                        
                        if st.button("Update Group", key=f"update_{group.id}"):
                            update_search_term_group(session, group.id, selected_terms)
                            st.success(f"Updated group: {group.name}")
                            st.rerun()
            else:
                st.info("No groups created yet.")
                
        with tab4:
            st.subheader("AI-Powered Search Term Grouping")
            ungrouped_terms = session.query(SearchTerm).filter(SearchTerm.group_id == None).all()
            if ungrouped_terms:
                st.write(f"Found {len(ungrouped_terms)} ungrouped search terms.")
                if st.button("Group Ungrouped Terms with AI"):
                    with st.spinner("AI is grouping terms..."):
                        grouped_terms = ai_group_search_terms(session, ungrouped_terms)
                        update_search_term_groups(session, grouped_terms)
                        st.success("Search terms have been grouped successfully!")
                        st.rerun()
            else:
                st.info("No ungrouped search terms found.")
                
        with tab5:
            st.subheader("Manage Search Term Groups")
            col1, col2 = st.columns(2)
            with col1:
                new_group_name = st.text_input("New Group Name")
                if st.button("Create New Group") and new_group_name:
                    create_search_term_group(session, new_group_name)
                    st.success(f"Created new group: {new_group_name}")
                    st.rerun()
            with col2:
                group_to_delete = st.selectbox(
                    "Select Group to Delete",
                    [f"{g.id}: {g.name}" for g in groups],
                    format_func=lambda x: x.split(":")[1] if ":" in x else x
                )
                if st.button("Delete Group") and group_to_delete:
                    group_id = int(group_to_delete.split(":")[0])
                    delete_search_term_group(session, group_id)
                    st.success(f"Deleted group: {group_to_delete.split(':')[1]}")
                    st.rerun()

def background_manual_search(process_id: str, search_terms: list, settings: dict):
    """Background process for manual search"""
    try:
        with db_session() as session:
            process_state = session.query(BackgroundProcessState).filter_by(process_id=process_id).first()
            if not process_state:
                return
                
            process_state.status = 'running'
            process_state.started_at = datetime.utcnow()
            session.commit()

            # Process each search term
            total_terms = len(search_terms)
            for idx, term in enumerate(search_terms):
                try:
                    # Update progress
                    progress = (idx + 1) / total_terms * 100
                    process_state.progress = progress
                    process_state.processed_items = idx + 1
                    process_state.total_items = total_terms
                    session.commit()

                    # Apply optimizations if selected
                    if settings['optimize_english']:
                        term = optimize_search_term(term, 'english')
                    if settings['optimize_spanish']:
                        term = optimize_search_term(term, 'spanish')
                    if settings['shuffle_keywords_option']:
                        term = shuffle_keywords(term)

                    # Perform search
                    results = manual_search(
                        session=session,
                        terms=[term],
                        num_results=settings['num_results'],
                        ignore_previously_fetched=settings['ignore_fetched']
                    )

                    # Save results to database
                    if results and isinstance(results, dict) and 'results' in results:
                        for result in results['results']:
                            save_lead(session, result)

                except Exception as e:
                    logging.error(f"Error processing term '{term}': {str(e)}")
                    continue

            # Update final status
            process_state.status = 'completed'
            process_state.completed_at = datetime.utcnow()
            process_state.progress = 100
            session.commit()

    except Exception as e:
        logging.error(f"Background search error: {str(e)}")
        if process_state:
            process_state.status = 'failed'
            process_state.error_message = str(e)
            process_state.completed_at = datetime.utcnow()
            session.commit()
        raise

def update_campaign_effectiveness(session, campaign_id):
    """Update campaign effectiveness metrics"""
    # Implementation
    pass

def get_campaign_effectiveness(session, campaign_id):
    """Get campaign effectiveness metrics"""
    # Implementation
    return {}

def update_lead_scores(session):
    """Update lead scores based on engagement"""
    # Implementation
    pass

def add_new_search_term(session, term, campaign_id):
    """Add a new search term"""
    search_term = SearchTerm(
        term=term,
        campaign_id=campaign_id,
        created_at=datetime.utcnow()
    )
    session.add(search_term)
    session.commit()
    return search_term

def get_page_description(html_content):
    """Extract page description from HTML content"""
    try:
        soup = BeautifulSoup(html_content, 'html.parser')
        meta_desc = soup.find('meta', {'name': 'description'})
        if meta_desc and meta_desc.get('content'):
            return meta_desc['content']
        return ""
    except Exception as e:
        logging.error(f"Error extracting page description: {str(e)}")
        return ""

def email_templates_page():
    """Email templates page implementation"""
    st.title("Email Templates")
    # Implementation details...
    pass

def bulk_send_page():
    """Bulk send page implementation"""
    st.title("Bulk Send Emails")
    # Implementation details...
    pass

def view_leads_page():
    """View leads page implementation"""
    st.title("View Leads")
    # Implementation details...
    pass

def view_campaign_logs():
    """View campaign logs page implementation"""
    st.title("Campaign Logs")
    # Implementation details...
    pass



# Update variable references
AIRequestLog = AIRequestLogs
SearchProcess = SearchProcesses
AutomationLogHandler = AutomationLogs

if __name__ == "__main__":
    main()



